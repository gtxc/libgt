threads:
  programs often need to do several things at the same time
  gmaes need to update the graphics on the screen while also reading input from a game controller
  chat programss will need to read text from the network and send data to the network at the same time
  media players will need to stream video to the display as well as watch for input from the use controls
  you need something that starts a separate task quickly, can share all of your current data,
  and will not require a lot of code to write, the answer is to use threads
  threads are a way to divide a single process into sub-runnable parts
    a separate path of execution inside a program
    sometimes called lightweight processes
  a thread can also be scheduled independently of the larger program that it is inside of (done by the OS)
    means that a single program may actually use more than 100% of CPU resources on multi-processor machines
  a thread has its own unique id, program counter (PC), a register set, and a stack space just like a process
  threads share memory across each thread by having the same address space (unlike multi-processes)
    two treads have access to the same set of variables and can alter each other's variable values
      if one thread changes a global variable, all of the other threads will see change immediately
  threads also share OS resources like open files and signals
    all of the threads will all be able to read and write to the same files and talk on the same network sockets
multi-threading:
  threads are popular way to improve an application through parallelism (simultaneous running of coe)
    several tasks can execute concurrently (many tasks can run in any order and possibly in parallel)
  a multi-threaded program is like a shop with several people working in it
  if one person is running in the checkout, another is filling shelves, and someone else is waxing the surfboards
    everbody can work without interruptions
    if one person answers the phone, it won't stop other people in the shop
  in the same way that several people can work in the same shop, you can have several threads living inside 
    the same process (program)
    each thread runs independently (a thread of execution)
  multi-threading means you can give each thread a separate task and they will all be performed at the same time
    in a browser, multiple tabs can be different threads
    MS word uses multiple threads, one thread to format the text, other thread to process inputs, etc.
advanteges of using threads:
  require less overhead than "forking" or spawning a new process
    the system does not initialize a new system virtual memory space and environment
  threads provide efficient communication and data exchange because they share the same address space
  threaded applications offer potential performance gains and practical advantages over non-threaded
    applications in severa ways
    thre creation of a thread is much faster (much less operating system overhead)
    faster context switching
    faster termination of a thread
disadvantages of using threads:
  very easy to overlook the consequences of interactions between concurrently executing threads
    considerable potential for very obscure errors in your code
  providing for thread synchronization is the biggest issue
    the potential for two or more threads attempting to access the same data at the same time
  imagine a program with several threads that may access a variable containing salary data
  suppose that two independent threads can modify the value
  if one thread access the value to change it and the second thread does the same before the first
    thread has stored the modified value
    you will have inconsistent data
  dead-locks and racing conditions
C is a language that runs on one thread by default (main), which means that the code will only run
  one instruction at a time
C does not contain any built-in support for multithreaded applications
  unless you count C11, but, these threads are not very portable and not widely supported
threading was traditionally provided via hardware and OS support in the past
  implementations differed substantially from each other making it difficult for programmers
    to develop protable threaded applications
in order to take full advantage of the capabilities provided by threads, a standardized programming
  interface was required
in 1995, POSIX became the standard interface for many system calls UNIX including the threading environment
we are going to write multi-threaded C programs using POSIX threads
  also know as pthreads, implemntation is available with the gcc compiler
    the key model for programming with threads in nearly every language (java, python and other high level languages)
POSIX thread (pthread) libraries:
  the POSIX thread libraries are a standards based thread API for C/C++
    allows one to spawn a new concurrent process flow
    can be found on almost any modern POSIX-compilant OS
  it is most effective on multi-processor or multi-core systems where the proces flow can be
    scheduled to run on another process
    thus gaining speed through parallel or distributed processig
  a thread is spawned by defining a function and it's arguments which will be processed in the thread
  the purpose of using POSIX thread library in your software is to execute software faster
  pthread functions are defined in a <pthread.h> header file and implemented in a thread library
  the functions that comprise the pthreads API can be grouped into three major categories:
    thread management:
      routines that work directly on threads-creating, detaching, joining, etc.
      also include functions to set/query thread attiributes (joinable, scheduling, etc.)
    synchronization:
      routines that manage read/write lock and barriers and deal with synchronization
      mutex functions provide for creating, destroying, locking and unlocking mutexes (mutual exclusion)
    condition variable:
      routines that address communications between threads that share a mutex
      based upon programmer specified conditions
  operations that can be performed on threads include:
    thread creation
    termination
    synchronization (joins, blocking)
    scheduling
    data management
    process interaction
  creating a thread:
    the lifecycle of a thread, much like a process, begins with creation
      threads are not forked from a parent to create a child
      instead they are simply created with a starting function as the entry point
    pthread_create():
      is called to create a new thread and make it executable
      initially, your main() program comprises a single, default thread and all other threads must
        be explicitly created by the programmer
      the maximum number of threads that may by created b a process is implementation dependent
        once created, threads are peers, and may create other threads
        there is no implied hierarchy dependency between threads
      int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void*), void *arg);
      takes 4 arguments
      the first argument is of type pthread_t
        an integer used to identify the thread in the system
        upon successful completion, pthread_create() stores the ID of the created thread in the location
          referenced by thread
      the second argument specifies attributes for the thread
        you can specify a thread attributes object, or NULL for the default values
        examples of attributes that can be specified include detached state, scheduling policy,
          scope, stack address and stack size
      the third argument is name of the function that the thread will execute once it is created
      the fourth argument is used to pass arguments to the function (start_routine)
        a pointer cast of type void is required
        NULL may be used if no argument is to be passed
        to pass multiple arguments, you would need to use a pointer to a structure
    pthread_join():
      is often useful to be able to identify when a thread has completed or exited
      the method for doing this is to join the thread, which is a lot like the wait() call for processes
      a join is performed when one wants to wait for a thread to finish
        used to link the current thread process to another thread
        a thread calling routine may launch multiple threads then wait for them to finish to get the results
      a call to pthread_join blocks the calling thread until the thread with identifier equal to the first
        argument terminates
        makes the program stops in order to wait for the end of the selected thread
      typically, only the main thread calls join, but other threads can also join each other
      all threads are automatically joined when the main thread terminates
      also receives the return value of your thread function and stores it in a void pointer variable
        once both threads have finished, your program can exit smoothly
      int pthread_join(pthread_t thread, void **value_ptr);
      the first argument is the thread id of the thread you want to wait for
      if the second argument is not NULL, this value is passed to pthread_exit() by the terminating thread
    pthread_exit():
      threads can be terminated in a number of ways
        by explicitly calling pthread_exit
        by letting the thread function return
        by a call to the function exit which will terminate the process including any threads
      typically, pthread_exit routine is called after a thread has completed its work and is no longer require to exit
      if main() finishes before the threads it has created finish, and exits with pthread_exit, the other
        threads will continue to execute
        otherwise, they will be automatically terminated when main() finishes
      although not explicitly require to call pthread_exit at the end of the thread function
        it is good practice to do so, as you may have the need to return some arbitrary data back to the
          caller via pthread_join
      void pthread_exit(void *value_ptr);
      the first argument makes the value_ptr available to any successful join with the terminating thread
      sometimes it is desired for a thread not to terminate (a server with a worker thread pool)
        can be solved by placing the thread code in an infinite loop and using condition variables
  common thread functions:
    pthread_self():
    pthread_detach():
      when a thread is created, one of its attributes defines whether it is joinable or detached
        by default if you passed NULL as the second argument the thread will be in joinable state
        only threads that are created as joinable can be joined
          if a thread is created as detached, it can never joined
      if you know in advance that a thread will never need to join with another thread, consider creating
        it in a detached state
        some system resources may be able to be freed
      there are two common use cases of when you would want to detach:
        in a cancallation handler for a pthread_join()
          nearly essential to have a pthread_detach() function in order to detach the thread on which
            pthread_join() was waiting
          in order to detach the "initial thread" (as may be desirable in process that set up server threds)
        the pthread_detach() routine can be used to explicitly detach a thread even though it was created as joinable
        int pthread_detach(pthread_t thread);
  stack management:
    the POSIX standard does not dictate the size of a thread's stack
      implementation dependent and varies
    exceeding the default stack limit is often very easy to do
      results in program termination and/or corrupted data
    safe and potable programs do not depend upon the default stack limit
      instead, explicitly allocate enough stack for each thread by using the pthread_attr_setstacksize() function
    pthread_attr_getstacksize(attr, stacksize);
    pthread_attr_setstacksize(attr, stacksize);
  pthread_equal():
    compares two thread ids
      if the two ids are different 0 is returned, otherwise non-zero value is returned
      operator == should not be used to compared two thread ids against each other
    pthread_equal(thread1, thread2);
  pthread_once():
    executes the init_routine exactly once in a process
      the first call to this function by any thread in the process executes the given init_routine, without parameters
      any subsequent call will have no effect
    pthread_once(once_control, init_routine);
    the init_routine routine is typically an initialization routine
    the once_control parameter is a synchronization control structure that requires initialization prior to calling
      pthread_once
        pthread_once_t once_control = PTHREAD_ONCE_INT;
  thread synchronization concepts:
    is the concurrent execution of two or more threads that share critical resources
    threads should be synchronized to avoid critical resource use conflicts
      otherwise, conflics may arise when parallel-running threads attempt to modify a common variable at the same time
    race conditions:
      while the code may appear on the screen in the order you wish the code to execute
        threads are scheduled by the OS and are executed at random
      it cannot be assumed that threads are executed in the order they are created
        they may also execute at different speeds
      when threads are executing (racing to complete) they may give unexpected results (race condition)
      a race condition often occrs when two or more threads need to perform operations on the same memory area
        but the results of computations depends on the order in which these operations are performed
      may occur when commands to read and write a large amount of data are received at almost the same instant
        the machine attempts to overwrite some or all of the old data while that old data is still being read
    deadlocks:
      can occur when multiple threads are trying to access a shared resource
      is a situation in which two threads are sharing the same resource and effectively preventing each oter
        from accessing this resource
        causes program execution to halt indefinitely
        each thread is waiting on the other thread
      traffic gridlock is an everday example of a deadlock situation
      the dining philosophers problem is a common example of a deadlock
        each philosopher picks up his or her left fork and waits for the right fork to become available,
          but it never does
      deadlocks occur when one thread "locks" a resource never "unlocks" that resource
        caused by poor application of "locks" or joins
        you have to be very careful when applying two or more "locks" to a section of code
  thread safe code:
    because of the issues of race conditions and deadlocks a threaded function must call functions which are
      "thread safe"
      code only manipulates shared data structures in a manner that ensures that all threads behave properly
        without unintended interaction
    means that there are no static ot global variables (shared resources) which other threads may corrupt or
      clobber
      usually any function that does not use static data or other shared resources is thread-safe
    means that the program protects shared data
      possibly through the use of mutual exclusion, atomic operations or condition variables
      you want to strive to write "thread-safe" code
    thread-unsafe functions may be used by only one thread at a time in a program and the uniqueness of the
      thread must be ensured
  mutual exclusion:
    a critical section of code is code that contains a shared resource and is accessible by multiple proceses or
    threads
      it is important for a thread programmer to minimize critical sections if possible
    mutual exclusion is when a process or a thread is prevented simultaneous access to a critical section
      a property of concurrency control which is used to prevent race conditions
    is the method of serializing access to shared resources
    you do not want a thread to be modifiying a variable that is already in the process of being modified by
      another thread
    another scenario is where a value is in the process of being updated and another thread reads an old value
  mutexes:
    is alock that one can virtually attach to some resource
    one of the primary means of implementing thread synchronization and for protecting shared data
      used to prevent data inconsistencies due to race conditions
    anytime a global resource is accessed by more than one thread the resource should have a mutex assocated
      with it
      can apply a mutex to protect a segment of memory ("critical region") from other threads
    if a thread wishes to modify or read a value from a shared resource, the thread must first gain the lock
      once it has the lock it may do wat it wants with the shared resource without concerns of other threads
        accessing the shared resource because other threads will have to wait
      once the thread finishes using the shared resource, it unlocks the mutex, which allows other threads to
        access the resources
    as an analogy, you can think of a mutex as a safe with only one key and the resource it is protecting lies
      within the safe
      only one person can have the key to the chest at any time, therefore, is the only person allowd to look
        or modify the contents of the chest at the time it holds the key
    are one way of synchronizing access to shared resources
    when protecting shared data, it is the programmer's responsibility to make sure every thread that
      needs to use a mutex does so
      if four threads are updating the same data, but only one uses a mutex, the data can still be corrupted
    very often the action performed by a thread owning a mutex is the updating f gloabal variables
      a safe way to ensure that when several threads update the same variable, the final value is the
        same as what it would be if only one thread performed the update
    a typical sequence in the use of a mutex is as follows:
      create and initalize a mutex variable
      several threads attempt to lock the mutex
      only one succeeds and that thread owns the mutex
      the owner thread performs some set of actions
      the owner unlocks the mutex
      another thread acquires the mutex and repeats the process
      finally the mutex is destroyed
    when several threads complete for a mutex, the losers block at that call
    plase understand that a deadlock can occur when using a mutex lock
      making sure threads acquire locks in an agreed order (preservation of lock ordering)
    creating and destroying mutexes:
      mutex variables must be declared with type pthred_mutex_t
        they must be initialized/created before they can be used
      there two ways to initialize/create a mutex variable
      staticly, when it is declared:
        the below is a mutex variable named lock that is initialized to the defautl pthread mutex values
        pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
      dynamically, with the pthread_mutex_init() function:
        int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr);
        this functions requires a pthread_mutex_t variable to operate on as the first argument
        attributes for the mutex can be given through the second parameter
          to specify default attributes, pass NULL as the second parameter
        the pthreads standard defines three optional mutex attributes
          protocol: specifies the protocol used to prevent priority inversions for a mutex
          proceiling: specifies the priority ceiling of a mutex
          process-shared: specifies the process sharing of a mutex
        the pthread_mutex_destroy(mutex) function should be used to free mutex object which is no
          longer needed
    locking and unlocking mutexes:
      to perform mutex locking and unlocking, the pthreads library provides the following functions
      int pthread_mutex_lock(pthread_mutex_t *mutex);:
        used by a thread to acquire a lock on the specified mutex variable
        if the mutex is already locked by another thread, this call will block the calling thread until
          the mutex is unlocked
      int pthread_mutex_trylock(pthread_mutex_t *mutex);:
        will attempt to lock a mutex, however if the mutex is already locked, the routine will return
          immediately with a "busy" error code
        may be useful in preventing deadlock conditions, as in a priority-inversion situation
      int pthread_mutex_unlock(pthread_mutex_t *mutex);:
        will unlock a mutex if called by the owning thread
        calling this function is required after a thread has completed its use of protected data if
          other threads are to acquire the mutex for their work with the protected data
        and error will be returned if
          if the mutex was already unlocked
          if the mutex is owned by another thread
      anytime a global resource is accessed by more than one thread the resource should have a mutex
        associated with it
        the above functions should be used to control access to a "critical section" of code from
          other threads
        it is up to the programmer to ensure that the necessary threads all make the mutex lock and
          unlock calls correctly
  atomic operations and condition variables:
    allow for concurrent algorithms and access to certain shared data types without the use of mutexes
      one can modify some variable within a multithreaded context wihtout having to go through a locking protocol
    condition variables allwo threads to synchronize to a value of a shared resource
      used as a notification system between threads
    you could have a counter (flag) that once it reaches a certain amount
      a thread will activate and then wait on a condition variable
    active threads will signal on this condition variable to notify other threads waiting/sleeping on this
      condition variable
      causing a waiting thread to wake up
    you can also use a broadcast mechanism if you want to signal threads waiting on the condition
      variable to wakeup
    when waiting on condition variables, the wait should be inside a loop

  the threads library (pthread.h) provides three synchronization mechanisms that we can implement
    mutexes: locks, block access to variable by other threads
    joins: makes a thread wait till others are complete (terminated)
    condition variables: a way to communicate to other threads
  condition variable:
    provides yet another way for threads to synchronize
    while mutexes implement synchronization by controlling thread access to data, condition variables
      allow threads to synchronize based upon the actual value of data
    wihtout condition variables, the programmer need to have threads continually polling (possibly
      in a critical section), to check if a condition is met
      can be very resource consuming since the thread would be continuously busy in this activity
    a condition variable is a way to achieve the same goal without polling
    the condition variable mechanism allows threads to suspend execution and relinquish the processor
      until some condition is true
      used with the appropriate functions for waiting and later, thread continuation
    a condition variable must always be associated with a mutex
      to avoid a deadlock created by one thread preparing to wait and another thread which may signal
        the condition before the first thread actually waits on it
      the thread will be perpetually waiting for a signal that is never sent
    any mutex can bu used with a condition variable
      there is no explicit link between the mutex and the condition variable
    you can think of a condition variable as a "big pillow" in the sense that threads can fall asleep
      on a condition variable and be woken from that condition variable
    here is an analogy of how a condition variable can work:
      tommy the thread wanted to access shared information
        he acquired the appropirate lock but then was disappointed to see that the shared information
          was not ready yet
        without anything else to do, he ecided to sleep (or wait) on a nearby condition variable until
          another thread updated the shared information and woke him up
      timmy the thread finally came along and updated the shared information while tommy was sleep
        on the nearby condition variable
        timmy noticed tommy asleep, so timmy signaled him to wake up off the condition variable
        timmy then went on his way and left tommy to play with his new, excited shared information
    one thing that was missed in the above analogy is we know that to access the shared information
      a thread needs to hold a locl
      since timmy needs to update the shared information while tommy is asleep and waitin
        we must have any thread that sleeps on a condition variable release the lock while it is asleep
        but since tommy had the lock when he fell asleep, he expects to still have the lock when
          he wakes up
        so the condition variable semantics guarantee that a thread sleeping on a condition variable
          will not fully wake up until
          it receives a wake-up signal
          it can re-acquire the lock that it had when it fell asleep
    condition variables must be declared with type pthread_cond_t, and must be initialized before
      they can be used
    creating/destroying:
      pthread_cond_init(condition, attr) - dynamically created
      pthread_cond_t cond = PTHREAD_COND_INITIALIZER; - statically declared)
      phtread_cond_destroy(condition)
    waiting on condition:
      pthread_cond_wait - will put the caller thread to sleep on the condition variable condition and
        release the mutex lock, guaranteeing that when the subsequent line is executed after the caller
        has woken up, the caller will hold lock
      pthread_cond_timedwait - place limit on how long it will block
    waking thread based on condition:
      pthread_cond_signal
      pthread_cond_broadcast - wake up all threads blocked by the specified condition variable
    for all of the above functions, the caller must first hold the lock that is assoiated with that
      condition variable
      failure to do this can lead to several problems